library(lubridate)
library(tidyr)
library(ggplot2)
library(gsheet)
library(tictoc)
library(data.table)
library(dplyr)
library(reticulate)
library(patchwork)
library(here)
library(stringr)

source(here("scripts/tracking_analysis_functions.R"))
source(here("scripts/peak_finding_functions.R"))

#######################################################################################################################
####### LOAD IN GOOGLE SHEET DATA #####################################################################################
#######################################################################################################################

# The following loads in the meta data from the google sheet. The url is the same as the 'share' link (generated by the share button in google sheets)
# This uses two functions - 'read.csv', which is a base R function, and 'gsheet2text' which comes from package 'gsheet'

url <- 'https://docs.google.com/spreadsheets/d/1Als2BdcYRUUWP4X5Np7WpfKt2YPMIz_55W3ktx5DOh4/edit?usp=sharing'
meta_data <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)

meta_data$sample_id <- paste("FISH", meta_data$Date..started., "_c", meta_data$Camera, "_r", meta_data$ROI, sep = "")
# You can use 'dim()' or 'head()' to quickly examine the results dataframe to see if it's correct
dim(meta_data)
head(meta_data)

####### IDENTIFY THE FILES FOR IMPORT #######

# List the files in the current directory that are als files
# This also finds the original runs for brichardi and crassus which have been transferred
# These need to be analysed differently (different times)
als.files <- list.files(path = "/Volumes/BZ/Scientific Data/RG-AS04-Data01/Hybrid_sleep_videos/_analysis2/", recursive = TRUE, pattern = "als.csv")


#######################################################################################################################
####### RUN THE COMMANDS TO IMPORT DATA ###############################################################################
#######################################################################################################################

# This imports a list of files
als.data.list <- lapply(als.files, function(x) loadALSfiles(path_to_file = x, average_by = "minute"))

names(als.data.list) <- als.files

## Can then save out the files for re-use
saveRDS(als.data.list, file = "als_data_list_hybrids.rds")

als.data.list <- readRDS("als_data_list_hybrids.rds")

als.data.list.2 <- lapply(als.data.list, function(x) summariseALSdata(als_data = x, average_by = "halfhour"))


#######################################################################################################################
####### MAKE PLOTS FOR INDIVIDUAL FISH ################################################################################
#######################################################################################################################

# Plot all days for an invidual, first set all days to '01' in a new datetime column called 'daytime'
als.data.list.2 <- lapply(als.data.list.2, function(x) {
  x$daytime <- as.POSIXct(x$datetime, format = '%Y-%m-%d %H:%M:%S')
  day(x$daytime) <- 01
  return(x)
})

all_days_plots <- lapply(als.data.list.2, function(x) {
  if (grepl("FISH20210205", x$sample_id[1]) | grepl("FISH20220216", x$sample_id[1])) {
    return(ggplot(x, aes(x = daytime, y = mean_speed_mm, group = day, colour = day)) + geom_rect_shading_zoo() + shade_colours() + geom_point() + geom_line() + ylim(0,120) + ggtitle(paste(x$sample_id[1])))
  } else {
    return(ggplot(x, aes(x = daytime, y = mean_speed_mm, group = day, colour = day)) + geom_rect_shading_bz() + shade_colours() + geom_point() + geom_line() + ylim(0,120) + ggtitle(paste(x$sample_id[1])))
  }
})

names(all_days_plots) <- unlist(lapply(als.data.list.2, function(x) x$sample_id[1]))

# This averages by day for a single dataset
# Importantly, ignore the single entry for day 1 when setting 'days_include'. For example, if you want the first 3 days, do 'days_include = c(1,2,3)' NOT 'days_include = c(2,3,4)'
avg.day.list <- lapply(als.data.list.2, function(x) averageDay(als_data = x, units = "halfhour", days_include = "all"))

avg_day_plots <- lapply(avg.day.list, function(x) {
  if (grepl("FISH20210205", x$sample_id[1]) | grepl("FISH20220216", x$sample_id[1])) {
    return(ggplot(x, aes(x = datetime, y = mean_speed_mm)) + geom_rect_shading_zoo() + shade_colours() + geom_point() + geom_line() + ylim(0,120) + ggtitle(paste(x$sample_id[1])))
  } else {
    return(ggplot(x, aes(x = datetime, y = mean_speed_mm)) + geom_rect_shading_bz() + shade_colours() + geom_point() + geom_line() + ylim(0,120) + ggtitle(paste(x$sample_id[1])))
  }
})

names(avg_day_plots) <- unlist(lapply(als.data.list.2, function(x) x$sample_id[1]))


#######################################################################################################################
#### Find peaks #######################################################################################################
#######################################################################################################################
dist <- 4
prom <- 7

# Find peaks across the week
avg.day.list <- lapply(avg.day.list, function(x) findPeaks(als_data = x, distance = dist, prominence = prom))
# ... and for the average day
als.data.list.2 <- lapply(als.data.list.2, function(x) findPeaks(als_data = x, distance = dist, prominence = prom))

### Return peak_percentages for the week and average day
percentages.day <- lapply(avg.day.list, function(x) {
  if (grepl("FISH20210205", x$sample_id[1]) | grepl("FISH20220216", x$sample_id[1])) {
    y <- returnPeakPercentages(als_data = x, avg_days = TRUE, zoo_times = TRUE)
  } else {
    y <- returnPeakPercentages(als_data = x, avg_days = TRUE)
  }
  return(y)
})

percentages <- lapply(als.data.list.2, function(x) {
  if (grepl("FISH20210205", x$sample_id[1]) | grepl("FISH20220216", x$sample_id[1])) {
    y <- returnPeakPercentages(als_data = x, avg_days = FALSE, zoo_times = TRUE)
  } else {
    y <- returnPeakPercentages(als_data = x, avg_days = FALSE)
  }
  return(y)
})

### Return peak_prominences for the week and average day
prominences.day <- lapply(als.data.list.2, function(x) {
  if (grepl("FISH20210205", x$sample_id[1]) | grepl("FISH20220216", x$sample_id[1])) {
    y <- returnPeakProminences(als_data = x, avg_days = TRUE, zoo_times = TRUE)
  } else {
    y <- returnPeakProminences(als_data = x, avg_days = TRUE)
  }
  return(y)
})

prominences <- lapply(als.data.list.2, function(x) {
  if (grepl("FISH20210205", x$sample_id[1]) | grepl("FISH20220216", x$sample_id[1])) {
    y <- returnPeakProminences(als_data = x, avg_days = FALSE, zoo_times = TRUE)
  } else {
    y <- returnPeakProminences(als_data = x, avg_days = FALSE)
  }
  return(y)
})

### Combine into a dataframe with sample_ids
df <- tibble(dawn_percentages = unlist(lapply(percentages, function(x) x[[1]])), 
             dusk_percentages = unlist(lapply(percentages, function(x) x[[2]])), 
             dawn_avg_day_percentages = unlist(lapply(percentages.day, function(x) x[[1]])), 
             dusk_avg_day_percentages = unlist(lapply(percentages.day, function(x) x[[2]])), 
             sample_id = str_extract(als.files, pattern = "FISH........_c._r."))


df$percentages <- rowMeans(df[,c("dawn_percentages", "dusk_percentages")])
df$percentages_avg_day <- rowMeans(df[,c("dawn_avg_day_percentages", "dusk_avg_day_percentages")])

all_data <- merge(df, meta_data, by = "sample_id")
all_data <- all_data[order(all_data$dawn_percentages),]
all_data$sample_id <- factor(all_data$sample_id, levels = all_data$sample_id)

all_data$Generation_group <- ifelse(all_data$Generation %in% c("P0_BRI", "P0_CRA"), "P0", "F1_F2_F3")

# ## This is a good output, tells me how many fish per generation type average a peak at dawn or dusk, or the combined values
# table(all_data$dawn_avg_day_percentages, all_data$Generation)
# table(all_data$dusk_avg_day_percentages, all_data$Generation)
# table(all_data$percentages_avg_day, all_data$Generation)

cor(all_data$dawn_percentages[all_data$Generation_group == "P0"], all_data$dusk_percentages[all_data$Generation_group == "P0"])
cor(all_data$dawn_percentages[all_data$Generation_group == "F1_F2_F3"], all_data$dusk_percentages[all_data$Generation_group == "F1_F2_F3"])

cor(all_data$dawn_percentages[all_data$Generation == "P0_BRI"], all_data$dusk_percentages[all_data$Generation == "P0_BRI"])
cor(all_data$dawn_percentages[all_data$Generation == "P0_CRA"], all_data$dusk_percentages[all_data$Generation == "P0_CRA"])
cor(all_data$dawn_percentages[all_data$Generation %in% c("F1", "F2", "F3")], all_data$dusk_percentages[all_data$Generation %in% c("F1", "F2", "F3")])

#######################################################################################################################
####### Make PEAK PLOTS ###############################################################################################
#######################################################################################################################

summary <- merge(df, meta_data, by = "sample_id")
summary$plot_gen <- ifelse(summary$Generation %in% c("F1", "F2", "F3"), "F1-F2-F3", summary$Generation)
summary$plot_gen <- factor(summary$plot_gen, levels = c("P0_BRI", "P0_CRA", "F1-F2-F3"))

## Sort and plot crepuscular percentages
summary$sample_id <- factor(summary$sample_id, levels = unique(summary$sample_id[with(summary, order(percentages))]))
plot_crepuscular <- ggplot(summary, aes(x = sample_id, y = percentages, fill = percentages)) + 
  scale_fill_distiller(palette = "BrBG") +
  geom_line() + 
  geom_point(shape = 22, colour = "black", size = 2) + 
  theme_classic() + 
  theme(legend.position = "none", axis.text.x = element_blank(), axis.text = element_text(colour = "black")) + 
  ylab("Crepuscularity") +
  xlab("Hybrid individuals")

# plot_crepuscular <- plot_crepuscular + facet_wrap(~plot_gen, ncol = 3)

### AND/OR a density plot?

plot_crepuscular_density <- ggplot(summary, aes(y = percentages, group = plot_gen, colour = plot_gen, fill = plot_gen)) + 
  geom_density(alpha = 0.25) +
  theme_classic() + 
  theme(axis.text = element_text(colour = "black")) + 
  xlab("Density") +
  ylab("Crepuscularity")

plot_crepuscular_density 



pdf(file = here("QTL_analysis.pdf"), width = 10, height = 2)
plot_crepuscular + plot_crepuscular_density + plot_layout(ncol = 2, widths = c(10, 1.5))
dev.off()







bar_plot_dawn <- ggplot(all_data, aes(x = sample_id, y = dawn_percentages, fill = Generation)) + theme_classic() + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90))

x_y <- ggplot(all_data, aes(x = dawn_percentages, y = dusk_percentages, colour = Generation, group = Generation)) + theme_classic() + geom_smooth(method = "lm", fill = "transparent")  + stat_cor()  + geom_jitter() + theme(axis.text.x = element_text(angle = 90))
dawn_density <- ggplot(all_data, aes(x = dawn_percentages, colour = Generation)) + theme_classic() + geom_density()
dusk_density <- ggplot(all_data, aes(x = dusk_percentages, colour = Generation)) + theme_classic() + geom_density() + coord_flip()

x_y_2 <- ggplot(all_data, aes(x = dawn_percentages, y = dusk_percentages, colour = Generation_group, group = Generation_group)) + theme_classic() + geom_smooth(method = "lm", fill = "grey95")  + stat_cor() + geom_jitter() + theme(axis.text.x = element_text(angle = 90))
dawn_density_2 <- ggplot(all_data, aes(x = dawn_percentages, colour = Generation_group)) + theme_classic() + geom_density()
dusk_density_2 <- ggplot(all_data, aes(x = dusk_percentages, colour = Generation_group)) + theme_classic() + geom_density() + coord_flip()

all_data <- all_data[order(all_data$dusk_percentages),]
all_data$sample_id <- factor(all_data$sample_id, levels = all_data$sample_id)
bar_plot_dusk <- ggplot(all_data, aes(x = sample_id, y = dusk_percentages, fill = Generation)) + theme_classic() + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90))


# Put them together to display
combined_plot <- dawn_density + plot_spacer() + x_y + dusk_density + plot_layout(ncol = 2, guides = "collect", widths = c(2,1), heights = c(1,2))
combined_plot_2 <- dawn_density_2 + plot_spacer() + x_y_2 + dusk_density_2 + plot_layout(ncol = 2, guides = "collect", widths = c(2,1), heights = c(1,2))

pdf(file = "summary_plots_BriCra_Hybrids_NEW.pdf", width = 10, height = 7.5)
combined_plot
dev.off()

pdf(file = "summary_plots_BriCra_Hybrids_Gen2_NEW.pdf", width = 10, height = 7.5)
combined_plot_2
dev.off()

pdf(file = "summary_histogram_BriCra_Hybrids_NEW.pdf", width = 15, height = 10)
bar_plot_dawn + bar_plot_dusk + plot_layout(nrow = 2)
dev.off()




## This plots the 'peak prominences' from the Python code
## But this plots all peaks, not just those within the right timepoint?
names(prominences) <- str_extract(als.files, pattern = "FISH........_c._r.")
df2 <- data.frame(prominences = unlist(prominences), sample_id = str_extract(names(unlist(prominences)), pattern = "FISH........_c._r."), period = str_extract(names(unlist(prominences)), pattern = "d..."))

all_data2 <- merge(df2, meta_data, by = "sample_id")

ggplot(all_data2, aes(x = Generation, y = prominences, group = interaction(period, Generation), color = interaction(period, Generation))) + geom_boxplot(outlier.colour = "white") + geom_jitter(alpha = 0.5) + theme_classic()

##### In general, it seems that the F2s and F3s have more peaks (especially at dusk), and their peaks are more prominent, than either parental strain
##### It's a bit clearer if I call peaks based on the daily average (eg if the invididual averages a peak)

## This is a crude way of plotting which points are 'peaks' according to the algorithm

# ggplot(als.data.list.2[[25]], aes(x = datetime, y = mean_speed_mm, color = peaks, group = sample_id)) + geom_rect_shading_bz_7days() + shade_colours() + geom_point() + geom_line(color = "black") + theme_classic()


#######################################################################################################################
####### Output all AVG DAY PLOTS ######################################################################################
#######################################################################################################################

### Can I make a big plot of all ranked by peak percentage?
### In this case, dawn peak_percentage
# combined_all_days_plots <- append(all_days_plots, append(all_days_plots_bri, all_days_plots_cra))
combined_all_days_plots <- all_days_plots[levels(all_data$sample_id)]

# combined_avg_day_plots <- append(avg_day_plots, append(avg_day_plots_bri, avg_day_plots_cra))
combined_avg_day_plots <- avg_day_plots[levels(all_data$sample_id)]

## Make a vector of indices for each 24th plot
lengths <- 1:length(combined_all_days_plots)
vector <- c(lengths[lengths %% 20 == 0], length(combined_all_days_plots))

## Use a for loop to print multiple pages of plots (24 each)
for (i in seq_along(vector)) {
  curr_var <- vector[i]
  if (i == 1) {
    prev_var = 1
  } else {
    prev_var = vector[i-1] + 1
  }
  
  pdf(file = paste("avg_day_plots_BriCra_Hybrids_page_", i, "_NEW.pdf", sep = ""), width = 16, height = 24)
  print(wrap_plots(combined_avg_day_plots[prev_var:curr_var], ncol = 4, guides = "collect"))
  dev.off()
}





# # ... and then averages across days by halfhour
# avg.day.list <- lapply(als.data.list, function(x) averageDay(als_data = x, units = "halfhour", days_include = "all"))
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# # Reduce the list into one dataframe
# avg.day.combined <- Reduce(rbind, avg.day.list)
# 
# # Add meta_data
# avg.day.combined <- merge(avg.day.combined, meta_data, by = "sample_id")
# 
# ## Then plot
# plot <- ggplot(avg.day.combined, aes(x = datetime, y = mean_speed_mm, group = sample_id, color = shell)) + geom_rect_shading_bz() + geom_point() + geom_line() + theme_classic()
# 
# ## Use 'facet_wrap' to separate based on columns in meta_data
# ## works like an equation ~ means 'by', and you can use addition ('shell+strain' or 'strain+conspecifics')
# plot + shade_colours() + facet_wrap(~shell+conspecifics, ncol = 2)
# 
# 
# plot + shade_colours() + facet_wrap(~conspecifics, ncol = 2)
# plot + shade_colours() + facet_wrap(~shell, ncol = 2)
# 
# 
# 
# 
# 
# #### Plot individuals, split by day
# 
# # This takes a single dataset and further summarises it by halfhour (probably not so useful, but can save space/computation time)
# als.data.2 <- summariseALSdata(als_data = als.data.list[[75]], average_by = "halfhour")
# 
# # Plot all days for an invidual, first set all days to '01'
# als.data.2$daytime <- as.POSIXct(als.data.2$datetime, format = '%Y-%m-%d %H:%M:%S')
# day(als.data.2$daytime) <- 01
# ggplot(als.data.2, aes(x = daytime, y = mean_speed_mm, group = day, colour = day)) + geom_rect_shading_bz() + shade_colours() + geom_point() + geom_line()
# 
# 
# avg.day <- averageDay(als_data = als.data.2, units = "halfhour", days_include = "all")
# ggplot(avg.day, aes(x = datetime, y = mean_speed_mm)) + geom_rect_shading_bz() + shade_colours() + geom_point() + geom_line()
# 
# 
# ## Run Python functions to find peaks
# ## Remember, python is 0 indexed, so add 1 to the indices
# 
# #scipy.signal <- import("scipy.signal")
# 
# week_peaks <- scipy.signal$find_peaks(x = als.data.2$mean_speed_mm, distance=4, prominence=7)
# avg_day_peaks <- scipy.signal$find_peaks(x = avg.day$mean_speed_mm, distance=4, prominence=7)
# 
# ## This is a crude way of plotting which points are 'peaks' according to the algorithm
# als.data.2$peaks <- "no"
# als.data.2$peaks[week_peaks[[1]]+1] <- "yes"
# ggplot(als.data.2, aes(x = datetime, y = mean_speed_mm, color = peaks, group = sample_id)) + geom_rect_shading_bz_7days() + shade_colours() + geom_point() + geom_line(color = "black") + theme_classic()
# 
# ggplot(als.data.2, aes(x = daytime, y = mean_speed_mm, group = day, colour = peaks)) + geom_rect_shading_bz() + shade_colours() + geom_point() + geom_line(color = "black") + theme_classic()
# 
# 
# avg.day$peaks <- "no"
# avg.day$peaks[avg_day_peaks[[1]]+1] <- "yes"
# ggplot(avg.day, aes(x = datetime, y = mean_speed_mm, color = peaks, group = sample_id)) + geom_rect_shading_bz() + shade_colours() + geom_point() + geom_line(color = "black") + theme_classic()
# 
# 
# ## What % of crep periods are there peaks? dawn vs dusk
# 
# als.data.2
# ## Make intervals for each dawn and each dusk
# ## Then for each, ask if there is a yes?
# 
# ## for loop to make intervals? 02, 03, 04, 05, 06, 07, 08
# 









